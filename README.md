# NGS_ligation-site-finding
Note: The work was done at the end of an internship and was not finished. Maybe the next intern will finish it. 

Provided is a fastq file from 2011 containing Illumina DNA sequencing data of different plant species.

The samples of the different species were first sequenced on their own with corresponding primers and then pooled together. As the sequencing methods in 2011 required a specific base length range, the DNA fragments were concatemerised with a DNA ligase and then cut, in order to obtain as much reading data as possible. After cutting the fragments into smaller fragments of 200-600 bp length via shearing, the ends were repaired using Klenow DNA polymerase and T4. During the end repair, a single adenine base was added to the 3' end of the blunted DNA. After A-tailing, the Illumina sequence adapters were ligated to the ends of the DNA fragments. Then, the DNA fragments were separated by length via gelelectrophoresis and only those with 300-350 bp length were cut out. The DNA was then sequenced with Illumina. 

Steps to process the sequencing data:

1) Data Cleaning, Trimming, Separating the DNA sequences at the ligation binding site

The sequences in the fastq file were already trimmed to get rid of the Illumina library adapters, but this was not documented. To check, see adapter sequence under following link:
https://support-docs.illumina.com/SHARE/AdapterSeq/Content/SHARE/AdapterSeq/Nextera/SequencesNXTILMPrepAndPCR.htm

It is not known whether bases were inserted during ligation and which bases this were. The aim is to find the ligation sites which correspond with the sites where a primer and the reverse complement of another primer meet. The potential inserted bases would lie in between these two primer sequences and must be removed. The sequences then need to be separated at this primer meeting sites to obtain the sequences of the DNA fragments before ligation. 

The fastq file was first analysed using R (see read_fastq) to obtain information about read length and quality distribution. As it seems, the program converting the reads into fastq format was attaching bases so that every read has the same length. As this attached bases also have a bad quality score, the graph about read quality distribution generated by the script is not correct. As for now, testing of the script for primer finding (see below) was done with the current fastq file, for the final results, a new fastq file must be generated. To accelerate the process, only the first 2500 sequences (=10 000 lines) were taken for testing, stored in short_sequence.fastq. This was done with the command head -n10000 NG-5514_pcr_R1.fastq >> short_sequence.fastq

The degenerated primer sequences were first reversed and complemented with an R script(see folder primer_reverse_complement). After that, duplicate sequences were removed and the code letters standing for degenerated bases were replaced with regular expressions, this was done with notepad++. To remove the fasta headers: sed -n '0~2p' primers_regex_unique.fasta > primer_cleaned.fasta
Following, a bash script using sed was written to mark the occurence of the primers, to see if bases were inserted during ligation. Result notes are stored in notizen_primerabstaende.

Next, the reads need to be separated and the new reads need to be renamed and stored in a new fastq file. This could be done by saving the indices of the sites of the desired separations in a file and then, after reading the fastq file in with an appropriate tool, separating and renaming the reads at the indices before converting it into a new fastq file. 

After the successfull separation of the DNA sequencing fragments, the next steps would be:

2) Mapping to the reference genomes of the corresponding plant species to group the DNA sequences by species

3) Alignment of the sequencing fragments to reconstruct the original whole genome DNA sequence

4) Analyse the sequences (e.g. search for SNPs)

